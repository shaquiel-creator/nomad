<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta content="IE=edge" http-equiv="X-UA-Compatible">
  <meta content="width=device-width,initial-scale=1" name="viewport">
  <meta content="description" name="description">
  <meta name="google" content="notranslate" />
  <meta content="Mashup templates have been developped by Orson.io team" name="author">

  <!-- Disable tap highlight on IE -->
  <meta name="msapplication-tap-highlight" content="no">

  <link rel="apple-touch-icon" sizes="180x180" href="./static/assets/apple-icon-180x180.png">
  <link href="./static/assets/favicon.ico" rel="icon">

  <title>Title page</title>

<link href="./static/main.3f6952e4.css" rel="stylesheet"></head>

<body class="">
<div id="site-border-left"></div>
<div id="site-border-right"></div>
<div id="site-border-top"></div>
<div id="site-border-bottom"></div>
<!-- Add your content of header -->
<header>
  <nav class="navbar  navbar-fixed-top navbar-default">
    <div class="container">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-collapse" aria-expanded="false">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>

      <div class="collapse navbar-collapse" id="navbar-collapse">
        <ul class="nav navbar-nav ">
          <li><a href="./index.html" title="">01 : Home</a></li>
          <li><a href="./works.html" title="">02 : Works</a></li>
          <li><a href="./about.html" title="">03 : About me</a></li>
          <li><a href="./contact.html" title="">04 : Contact</a></li>
        </ul>


          <ul class="nav navbar-nav navbar-right navbar-small visible-md visible-lg">
            <li><a href="./work1.html" title="" class="active" target="_blank">001</a></li>
            <li><a href="https://www.kaggle.com/aaysbt/house-price-eda-model-predictions" title="" target="_blank">002</a></li>
            <li><a href="https://www.kaggle.com/aaysbt/titanic-datasets-eda-fe-dc-model-predictions" title="" target="_blank">003</a></li>
            <li><a href="./work2.html" title="">004</a></li>
            <li><a href="https://medium.com/my-data-camp-journey/predictive-analysis-in-python-97ca5b64e97f" title="" target="_blank">005</a></li>
            <li><a href="https://medium.com/my-data-camp-journey/preprocessing-data-for-logistic-regression-f311c937d765:wq" title="" target="_blank">006</a></li>
          </ul>


      </div>
    </div>
  </nav>
</header>
<div class="section-container">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <img src="./static/assets/images/work1_1.png" class="img-responsive" alt="">
        <div class="card-container">
          <div class="text-center">
            <h1 class="h2">001 : Fashion MNIST dataset training using PyTorch</h1>
          </div>
          <p>This project is a part of the <a href="https://www.udacity.com/bertelsmann-tech-scholarships" target="_blank"> Bertelsmann Tech Scholarship AI Track Nanodegree Program from Udacity</a>. In this project, we are going to use Fashion MNIST data sets, which is contained a set of 28X28 greyscale images of clothes. Our goal is building a neural network using Pytorch and then training the network to predict clothes. This trained network will return a probability for 10 classes of clothes shown in images.</p>
          <br>
          <p>Let’s write down a route map to follow</p>
          <br>
          <img class="img-responsive" src="./assets/images/img_1_2.png">
          <br>
          <ul>
            <li>Load and visualize the data</li>
            <li>Pre-Process your data (Transform: Normalization, Converting into tensor)</li>
            <li>Define your model using Pytorch</li>
            <li>Training the model</li>
            <li>Save the Best model: find the best model using the validation dataset</li>
            <li>Test out your model</li>
          </ul>
          <h2>Importing Libraries</h2>
          <p>
            <script src="https://gist.github.com/aysbt/95e017c882788ea60bda79816ed03a75.js"></script>
          </p>
          <ul>
            <li><code>torch.optim</code> implement various optimization algorithms like SGD and Adam.</li>
            <li><code>torch.nn.functional</code> for non-linear activation functions like relu, softmin, softmax, logsigmoid, etc.</li>
            <li>The <em>torchvision packages</em> consist of popular datasets, model architectures, and common image transformations for computer vision. We are using datasets and transform from torchvision to download a fashion-MNIST dataset and transforms an image using compose transformations.</li>
            <li>Subset RandomSampler used to split the dataset into train and validation subsets for validation of our model.</li>
          </ul>
          <h2>Download Datasets and Transform Images</h2>
          <ol>
            <li>Extract — Get the <em>Fashion-MNIST</em> image data from the source</li>
            <li>Transform — Put our data into a tensor form.</li>
            <li>Load — Put our data into an object to make it easily accessible.</li>
          </ol>
          <p>
            <script src="https://gist.github.com/aysbt/ddadfc7c7d79b567849781b5be97c682.js"></script>
          </p>
          <ul>
            <li><code>transforms.Compose</code> creates a series of transformation to prepare the dataset.</li>
            <li><code>transforms.ToTenser</code> convert PIL image<em>(L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK, 1)</em> or  <mark>numpy.ndarray</mark> (H x W x C) in the range [0, 255] to a <mark>torch.FloatTensor</mark> of shape (C x H x W) in the range [0.0, 1.0].</li>
            <li><code>transform.Normalize</code> Normalize a tensor image with mean and standard deviation. Tensor image size should be (C x H x W) to be normalized which we already did use the <mark>transforms.ToTenser</mark>.</li>
            <li><code>datasets.FashionMNIST</code> to download the Fashion MNIST datasets and transform the data.The train paremeter set the True <em>(train=True)</em> to get trained dataset, otherwise set the parameter False for the test dataset.</li>
            <li><code>torch.utils.data.Dataloader</code> takes our data train or test data with parameter <em>batch_size and shuffle</em>. <em>batch_size</em> define the how many samples per batch to load, and <em>shuffle</em> parameter set the True to have the data reshuffled at every epoch.</li>
          </ul>
          <h2>Visualize a Batch of Training Data</h2>
          <p>
            <script src="https://gist.github.com/aysbt/3959da7c328d200e6528ec2766bc3907.js"></script>
          </p>
          <img src="./assets/images/in_1_1.png" class="img-responsive" alt="Training data with label">
          <h2>Building The Network</h2>
          <p>Our images are 28x28 2D tensors, so we need to convert them into 1D vectors. 784 is 28 times 28, so, this is typically called flattening, we flattened the 2D images into 1D vectors. This is our input layer and here we need to 10 output layers for the classification of the clothes.
          </p>
          <p> While we are defining the hidden layers, we are able to choose the arbitrary number. But this selection directly affects our neural network performance. We should modify the number to find out an optimized model for our image classification problem.</p>
          <img src="./assets/images/in_1_2.png" class="img-responsive" alt="Fully Connected Neural Network Model">
          <p><script src="https://gist.github.com/aysbt/49dcaf044abfc7210f43be3082f1d74b.js"></script></p>
          <ul>
            <li>Defining our Neural Network (NN)architectures using the python class.</li>
            <li>PyTorch provides a <code>nn.Module</code> that building neural networks.</li>
            <li><code>super().__init__()</code> this creates a class that tracks the architecture and provides a lot of useful methods and attributes.</li>
            <li>In <em>NN</em> architecture, we defined 3 hidden layers and 1 output layer.</li>
            <li><code>self.fc1 = nn.Linear(784, 256)</code>: This line creates a module for a linear transformation, <mark>xw+b</mark>, with 784 inputs and 256 outputs for first hidden layer and assigns it to <mark>self.fc1</mark>. The module automatically creates the weight and bias tensors which we'll use in the forward method.</li>
            <li>Similarly, the following lines create another linear transformation with 256 inputs and 128 output and so on.</li>
            <li>In forward model, we take tensor input x to change its shapes to our batch size using <mark>x.shape[0]</mark> , the <em>-1</em> fill out the second dimension.</li>
            <li>Then, we could pass thought operations that we defined in <mark>__init__</mark>. The input layer goes through the hidden layer with a together dropout and RELU activation function then reassign it to the <em>x</em>.</li>
            <li>For the output layer, we pass through the <mark>Log Softmax</mark>function to obtain the log-probabilities in neural-network.</li>
          </ul>
          <p><script src="https://gist.github.com/aysbt/69f6395bb8c3333090e385b89015e487.js"></script></p>
          <p>The training pass process is as follow:</p>
          <ul>
            <li><code>model = Classifier():</code> This line is actually create our model.</li>
            <li>Defined the criterion with Negative log-likelihood loss and also defined our optimizer (SGD)to optimize our model’s parameter when we loop through the dataset using epochs</li>
            <li>We are going to track running loss and validation loss for each epoch to see the evaluation of our model.</li>
            <li>For raining the data we set the model in train mode: <mark>model.train()</mark>. Then loop over the “trainloader” to extract images and labels from a train data. The following process shows the train pass.</li>
          </ul>
            <br>
            <p>
            <code>zero_grad():</code> Clear the gradients of all optimized variables<br>
            <code>log_ps = model(images):</code> Make a forward pass through the network to getting log probabilities bypassing the images to the model.<br>
            <code>loss = criterion(log_ps, lables):</code> Use the log probabilities (log_ps) and labels to calculate the loss.<br>
            <code>loss.backward():</code> Perform a backward pass through the network to calculate the gradients for model parameters.<br>
            <code>optimizer.step():</code> Take a step with the optimizer to update the model parameters.
            </p>
            <ul>
              <li>We need to use validation data to know when to stop training the model. So, we have validatiın batch that loop over the validation data and labels.</li>
              <li>In validation batch, we apply the model and calculate the loss for the validation data set. We are also going to trach the validation loss. We need to stop training whenever train loss decrease but validation loss does not.</li>
              <li>Print out the average training loss and validation loss, and then the model is going to save whenever the calculated validation loss is smaller than the saved validation loss.</li>
            </ul>
            <br>
            <img src="./assets/images/in_1_3.png" class="img-responsive">
            <br> <br>
            <p>We keep tracking the validation loss and train loss to investigate the averages values over time. The following plot shows averages values for train loss and validation loss which calculated for each epoch. </p> <br>
            <img src="./assets/images/in_1_4.png"  class="img-responsive" alt="Train Loss vs Validation Loss">
            <h2>Test the Trained Network</h2>
            <p>Finally, we test our best model on previously <strong>unseen test data</strong>. Testing on unseen data is a good way to check that our model.</p>
            <p><script src="https://gist.github.com/aysbt/e26bfcc2c55ac1548d4bff5466c03767.js"></script></p>
            <p>So, we come to the end. We would like the see how our model performs. For this, we are going the print out the accuracy of our model</p>
            <mark>
              Test Loss: 0.445839 <br>
              Test Accuracy of     0: 85% (859/1000)<br>
              Test Accuracy of     1: 95% (954/1000)<br>
              Test Accuracy of     2: 75% (752/1000)<br>
              Test Accuracy of     3: 86% (865/1000)<br>
              Test Accuracy of     4: 76% (766/1000)<br>
              Test Accuracy of     5: 90% (906/1000)<br>
              Test Accuracy of     6: 48% (482/1000)<br>
              Test Accuracy of     7: 91% (911/1000)<br>
              Test Accuracy of     8: 95% (953/1000)<br>
              Test Accuracy of     9: 93% (938/1000)<br>
              Test Accuracy (Overall): 83% (8386/10000)<br>
            </mark>
            <p>Then visualize the data to displays test images and their labels in the following format: <mark>predicted (ground-truth)</mark>. The text will be green for accurately classified examples and red for incorrect predictions.</p>
           <p><script src="https://gist.github.com/aysbt/010caca2972f6251e03a157e4b833d7a.js"></script></p>
           <img src="./assets/images/in_1_5.png" class="img-responsive">

           <p>Finally, completed the train and test our neural network. <a href="https://colab.research.google.com/drive/1nkAZaX5QQhnO3XN3FE27jW3JKk0tcPd_#scrollTo=JZcQH0Bto_Gy">This project</a> shows the road map for the basic neural network using Pytorch. Thank you so much Udacity and Bertelsmann to reach out to these courses.
           For the Note, I am still learner so, please let me know any additional information.</p>

           <p>Follow me on <a href="https://twitter.com/aaysbt">Twitter</a>

           </div>
      </div>

    </div>
  </div>
</div>


<footer class="footer-container text-center">
  <nav class="nav-footer">
    <p class="nav-footer-social-buttons">
      <hr style="width: 2px">
      <a class="fa-icon" href="https://www.linkedin.com/in/aysebat/" target="_blank" title="">
        <i class="fa fa-linkedin"></i>
      </a>
      <a class="fa-icon" href="https://github.com/aysbt/" target="_blank" title="">
        <i class="fa fa-github"></i>
      </a>
      <a class="fa-icon" href="https://twitter.com/aaysbt" target="_blank" title="">
        <i class="fa fa-twitter"></i>
      </a>
    </p>

  </nav>
</footer>

<script>
  document.addEventListener("DOMContentLoaded", function (event) {
     navActivePage();
  });
</script>

<!-- Google Analytics: change UA-XXXXX-X to be your site's ID

<script>
  (function (i, s, o, g, r, a, m) {
    i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
      (i[r].q = i[r].q || []).push(arguments)
    }, i[r].l = 1 * new Date(); a = s.createElement(o),
      m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
  })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
  ga('create', 'UA-XXXXX-X', 'auto');
  ga('send', 'pageview');
</script>

--> <script type="text/javascript" src="./static/main.70a66962.js"></script></body>

</html>
